{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNDlZSASf_Ii"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc, precision_score, recall_score, f1_score, classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from scipy import stats as st\n",
    "from random import randrange\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import optuna\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "o2QhR-UBf_In",
    "outputId": "2f974396-fda7-470b-ee29-92a627303ff1"
   },
   "outputs": [],
   "source": [
    "#Open csv file.\n",
    "\n",
    "data = pd.read_csv(\"./DMVO-NIHSS Shift/dmvo_final.csv\", index_col = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSMMUlwIhBt1",
    "outputId": "4da3bffa-f3d1-4904-9d35-099aae24b45d"
   },
   "outputs": [],
   "source": [
    "columns = data.columns.tolist()\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqK4cuwff_In"
   },
   "outputs": [],
   "source": [
    "#Define predictor variables and outcome of interest.\n",
    "\n",
    "variables = ['AGE', 'GLUCOSE', 'HR', 'SBP', 'DBP', 'SODIUM', 'POTASSIUM', 'CALCIUM', 'BUNCR', 'HGB', 'HTC', 'PLT', 'NEUPLT', 'MPV', 'MCV', 'ASPECTS', 'TIME_GROIN', 'RCBF20', 'RCBF30', 'RCBF34', 'RCBF38', 'TMAX4', 'TMAX6', 'TMAX8', 'TMAX10', 'CBV34', 'CBV38', 'CBV42', 'MISMATCH_VOL', 'HYPOPERF_INDEX', 'DWI_VOL', 'INFARCT_GROWTH', 'POST_NCCT', 'SEX_Female', 'SEX_Male', 'RACE_Black/African American', 'RACE_Other', 'RACE_White', 'AFIB_No', 'AFIB_Yes', 'DIABETES_No', 'DIABETES_Yes', 'HYPERTENSION_No', 'HYPERTENSION_Yes', 'MALIGNANCY_No', 'MALIGNANCY_Yes', 'CAD_No', 'CAD_Yes', 'IVTPA_No', 'IVTPA_Yes', 'HEMTRANS_No', 'HEMTRANS_Yes', 'THROMBECTOMY_No', 'THROMBECTOMY_Yes', 'PASS_1', 'PASS_2', 'PASS_3', 'PASS_4', 'PASS_Not attempted', 'MTICI_1', 'MTICI_2b', 'MTICI_2c', 'MTICI_3', 'MTICI_Not attempted', 'VESSEL_ACA', 'VESSEL_MCA', 'VESSEL_PCA', 'VESSEL_PICA', 'LATERALITY_Left', 'LATERALITY_Right', 'SEGMENT_A2', 'SEGMENT_M1-M2', 'SEGMENT_M2', 'SEGMENT_M3', 'SEGMENT_P1', 'SEGMENT_P2', 'SEGMENT_P3', 'LOCATION_Distal', 'LOCATION_Medial', 'LOCATION_Proximal', 'LOCATION_Unknown', 'NIHSS_SHIFT_CAT_Low shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBSEX4VOf_Io"
   },
   "outputs": [],
   "source": [
    "#Redefine data.\n",
    "\n",
    "data = data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ip8lAiZf_Io"
   },
   "outputs": [],
   "source": [
    "#Define predictor variables (x) and outcome of interest (y).\n",
    "\n",
    "x = data.drop(['NIHSS_SHIFT_CAT_Low shift'], axis = 1)\n",
    "y = data['NIHSS_SHIFT_CAT_Low shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zbKUEV4f_Ip",
    "outputId": "d8dea429-65b1-4367-d4e6-32fd66e4f9d3"
   },
   "outputs": [],
   "source": [
    "#Check data shapes.\n",
    "\n",
    "print(y.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FQRXlevf_Iq",
    "outputId": "4f07da0e-82fa-46d1-ecaa-cbc00323b7a9"
   },
   "outputs": [],
   "source": [
    "#Split data into train and test sets in 70:30 ratio.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#Describe train and test sets.\n",
    "\n",
    "print(\"Number patients x_train dataset: \", x_train.shape)\n",
    "print(\"Number patients y_train dataset: \", y_train.shape)\n",
    "print(\"Number patients x_test dataset: \", x_test.shape)\n",
    "print(\"Number patients y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo_WfwSnf_Ir",
    "outputId": "7b5d86c5-743a-4092-8cdb-b565a82bccb7"
   },
   "outputs": [],
   "source": [
    "#Describe outcome of interest before resampling.\n",
    "\n",
    "print(\"Before resampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before resampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRM4W-QTf_Ir"
   },
   "outputs": [],
   "source": [
    "#No resampling.\n",
    "\n",
    "x_rs = x_train\n",
    "y_rs = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkyvsQPuf_Is",
    "outputId": "06492e38-55aa-4d8c-ee84-c3b8fe50a238"
   },
   "outputs": [],
   "source": [
    "#Describe outcome of interest after resampling.\n",
    "\n",
    "print(\"After resampling, counts of label '1': {}\".format(sum(y_rs == 1)))\n",
    "print(\"After resampling, counts of label '0': {} \\n\".format(sum(y_rs == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXov3wLF8IIU"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoCvzQIrGuB-"
   },
   "outputs": [],
   "source": [
    "rfe_method = RFE(\n",
    "    RandomForestClassifier(n_estimators=10, random_state=10),\n",
    "    n_features_to_select=10,\n",
    "    step=1,\n",
    ")\n",
    "\n",
    "rfe_method.fit(x_rs, y_rs)\n",
    "\n",
    "selected_features = list(x_rs.columns[(rfe_method.get_support())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hh-nF3F8KOw1",
    "outputId": "cb8d94b9-fbd2-4cdc-e3d4-5243bd434b74"
   },
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfPxxTo4KoXL"
   },
   "outputs": [],
   "source": [
    "x_rs = x_rs[selected_features]\n",
    "x_test = x_test[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkJGQOtBf_It"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMr2ALhef_Iu",
    "outputId": "9e41c36e-41bf-47b6-a8cc-88caa308d2ce"
   },
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for XGBoost.\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = x_rs, y_rs\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
    "\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-auc\")\n",
    "\n",
    "    bst = xgb.train(param, dtrain, evals=[(dvalid, \"validation\")], callbacks=[pruning_callback])\n",
    "    preds = bst.predict(dvalid)\n",
    "    pred_labels = np.rint(preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(valid_y, pred_labels)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"maximize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    xgb_params = {}\n",
    "\n",
    "    for key, value in trial.params.items():\n",
    "        xgb_params[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "ql8dndbnf_Iv",
    "outputId": "41b88f93-2933-45b9-b17f-25373d7405ba"
   },
   "outputs": [],
   "source": [
    "#Fit XGBoost.\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(**xgb_params)\n",
    "\n",
    "xgb.fit(x_rs,y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zC5aqo-Of_Iw"
   },
   "outputs": [],
   "source": [
    "#Make predictions on the test set based on the trained XGBoost model.\n",
    "\n",
    "preds_xgb = xgb.predict(x_test)\n",
    "\n",
    "probs_xgb = xgb.predict_proba(x_test)\n",
    "probs_xgb = probs_xgb[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDUk12yMf_Iw",
    "outputId": "d63fe288-2180-4b1e-9d1c-68bf9efc4f9d"
   },
   "outputs": [],
   "source": [
    "#Evaluate XGBoost model.\n",
    "\n",
    "xgb_precision = precision_score(preds_xgb,y_test)\n",
    "xgb_recall = recall_score(preds_xgb,y_test)\n",
    "xgb_f1 = f1_score(preds_xgb,y_test)\n",
    "xgb_acc = accuracy_score(preds_xgb,y_test)\n",
    "xgb_mcc = matthews_corrcoef(y_test, preds_xgb)\n",
    "xgb_auroc = roc_auc_score(y_test, probs_xgb)\n",
    "\n",
    "print(\"Precision: %.3f\" % (xgb_precision))\n",
    "print(\"Recall: %.3f\" % (xgb_recall))\n",
    "print(\"F1 Score: %.3f\" %(xgb_f1))\n",
    "print('Accuracy: %.3f' % (xgb_acc))\n",
    "print('MCC: %.3f' % (xgb_mcc))\n",
    "print('AUROC: %.3f' % (xgb_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3In_Vihf_Ix",
    "outputId": "3c4d0746-7700-4edf-e20f-0558bcc6033c"
   },
   "outputs": [],
   "source": [
    "#Evaluate XGBoost model (PRC and AUPRC).\n",
    "\n",
    "xgb_precision, xgb_recall, _ = precision_recall_curve(y_test, probs_xgb)\n",
    "xgb_auprc = auc(xgb_recall, xgb_precision)\n",
    "\n",
    "print('AUPRC: %.3f' % (xgb_auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqvnghK1f_Iy"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision and recall for calculation purposes.\n",
    "\n",
    "xgb_precision = precision_score(preds_xgb,y_test)\n",
    "xgb_recall = recall_score(preds_xgb,y_test)\n",
    "\n",
    "xgb_results = [xgb_precision, xgb_recall, xgb_f1, xgb_acc, xgb_mcc, xgb_auroc, xgb_auprc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3YwnVgHf_Iy"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision recall curve for plotting purposes.\n",
    "\n",
    "xgb_precision, xgb_recall, _ = precision_recall_curve(y_test, probs_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2Z2wZWtf_Iy"
   },
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8yFGJMcf_Iz",
    "outputId": "71f1714b-1c0c-438e-8b35-55e1cb83fc43"
   },
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for LightGBM.\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = x_rs, y_rs\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    gbm = lgb.train(param, dtrain)\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(valid_y, pred_labels)\n",
    "    return auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    lgb_params = {}\n",
    "\n",
    "    for key, value in trial.params.items():\n",
    "        lgb_params[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "6o8_XpEUf_Iz",
    "outputId": "95f4823b-69d4-4efe-da02-9c87b119b48f"
   },
   "outputs": [],
   "source": [
    "#Fit LightGBM.\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "lgb.fit(x_rs, y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtJwUf4Qf_I0"
   },
   "outputs": [],
   "source": [
    "#Make predictions on the test set based on the trained model.\n",
    "\n",
    "preds_lgb = lgb.predict(x_test)\n",
    "\n",
    "probs_lgb = lgb.predict_proba(x_test)\n",
    "probs_lgb = probs_lgb[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARwvdz5qf_I0",
    "outputId": "90cc465c-e999-4cd7-8176-0e3248f2bef8"
   },
   "outputs": [],
   "source": [
    "#Evaluate LightGBM model.\n",
    "\n",
    "lgb_precision = precision_score(preds_lgb,y_test)\n",
    "lgb_recall = recall_score(preds_lgb,y_test)\n",
    "lgb_f1 = f1_score(preds_lgb,y_test)\n",
    "lgb_acc = accuracy_score(preds_lgb,y_test)\n",
    "lgb_mcc = matthews_corrcoef(y_test, preds_lgb)\n",
    "lgb_auroc = roc_auc_score(y_test, probs_lgb)\n",
    "\n",
    "print(\"Precision: %.3f\" % (lgb_precision))\n",
    "print(\"Recall: %.3f\" % (lgb_recall))\n",
    "print(\"F1 Score: %.3f\" %(lgb_f1))\n",
    "print('Accuracy: %.3f' % (lgb_acc))\n",
    "print('MCC: %.3f' % (lgb_mcc))\n",
    "print('AUROC: %.3f' % (lgb_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3EFf1jef_I0",
    "outputId": "26579e3c-28d3-402a-8087-b642051b4b08"
   },
   "outputs": [],
   "source": [
    "#Evaluate LightGBM model (PRC and AUPRC).\n",
    "\n",
    "lgb_precision, lgb_recall, _ = precision_recall_curve(y_test, probs_lgb)\n",
    "lgb_auprc = auc(lgb_recall, lgb_precision)\n",
    "\n",
    "print('AUPRC: %.3f' % (lgb_auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiyfN4Ilf_I1"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision and recall for calculation purposes.\n",
    "\n",
    "lgb_precision = precision_score(preds_lgb,y_test)\n",
    "lgb_recall = recall_score(preds_lgb,y_test)\n",
    "\n",
    "lgb_results = [lgb_precision, lgb_recall, lgb_f1, lgb_acc, lgb_mcc, lgb_auroc, lgb_auprc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsaas7klf_I1"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision recall curve for plotting purposes.\n",
    "\n",
    "lgb_precision, lgb_recall, _ = precision_recall_curve(y_test, probs_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1jelYZ3f_I1"
   },
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhlRfwZhf_I1",
    "outputId": "c47cb3aa-4d67-4f31-81e3-a18c111a8a4f"
   },
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for CatBoost.\n",
    "\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    data, target = x_rs, y_rs\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \"used_ram_limit\": \"3gb\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "    }\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log=True)\n",
    "\n",
    "    gbm = cb.CatBoostClassifier(**param)\n",
    "\n",
    "    pruning_callback = CatBoostPruningCallback(trial, \"AUC\")\n",
    "    gbm.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        eval_set=[(valid_x, valid_y)],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=100,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    # evoke pruning manually.\n",
    "    pruning_callback.check_pruned()\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(valid_y, pred_labels)\n",
    "\n",
    "    return auc\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5), direction=\"maximize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    cb_params = {}\n",
    "\n",
    "    for key, value in trial.params.items():\n",
    "        cb_params[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1TELeZ5f_I2",
    "outputId": "5de16736-eb9f-412b-e05a-433bdc80d280"
   },
   "outputs": [],
   "source": [
    "#Fit CatBoost.\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cb = CatBoostClassifier(**cb_params)\n",
    "\n",
    "cb.fit(x_rs,y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjQ8SutTf_I2"
   },
   "outputs": [],
   "source": [
    "#Make predictions on the test set based on the trained model.\n",
    "\n",
    "preds_cb = cb.predict(x_test)\n",
    "\n",
    "probs_cb = cb.predict_proba(x_test)\n",
    "probs_cb = probs_cb[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fd6GNgnmf_I2",
    "outputId": "4431a3fb-5ab2-454b-b175-41e1d085ed67"
   },
   "outputs": [],
   "source": [
    "#Evaluate CatBoost model.\n",
    "\n",
    "cb_precision = precision_score(preds_cb,y_test)\n",
    "cb_recall = recall_score(preds_cb,y_test)\n",
    "cb_f1 = f1_score(preds_cb,y_test)\n",
    "cb_acc = accuracy_score(preds_cb,y_test)\n",
    "cb_mcc = matthews_corrcoef(y_test, preds_cb)\n",
    "cb_auroc = roc_auc_score(y_test, probs_cb)\n",
    "\n",
    "print(\"Precision: %.3f\" % (cb_precision))\n",
    "print(\"Recall: %.3f\" % (cb_recall))\n",
    "print(\"F1 Score: %.3f\" %(cb_f1))\n",
    "print('Accuracy: %.3f' % (cb_acc))\n",
    "print('MCC: %.3f' % (cb_mcc))\n",
    "print('AUROC: %.3f' % (cb_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkZt_teUf_I3",
    "outputId": "b024b617-5c68-4ea5-ae94-87b180a229d4"
   },
   "outputs": [],
   "source": [
    "#Evaluate XGBoost model (PRC and AUPRC).\n",
    "\n",
    "cb_precision, cb_recall, _ = precision_recall_curve(y_test, probs_cb)\n",
    "cb_auprc = auc(cb_recall, cb_precision)\n",
    "\n",
    "print('AUPRC: %.3f' % (cb_auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzmNci9uf_I3"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision and recall for calculation purposes.\n",
    "\n",
    "cb_precision = precision_score(preds_cb,y_test)\n",
    "cb_recall = recall_score(preds_cb,y_test)\n",
    "\n",
    "cb_results = [cb_precision, cb_recall, cb_f1, cb_acc, cb_mcc, cb_auroc, cb_auprc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C15tT4lVf_I3"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision recall curve for plotting purposes.\n",
    "\n",
    "cb_precision, cb_recall, _ = precision_recall_curve(y_test, probs_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3-sp7ICf_I3"
   },
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxweXxmNf_I4",
    "outputId": "44bdea2c-df5f-4488-db41-0f211e70a731"
   },
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for Multi-Layer Perceptron.\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    data, target = x_rs, y_rs\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "\n",
    "    param = {\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1, 12),\n",
    "        \"activation\": trial.suggest_categorical(\"activation\", [\"tanh\", \"relu\"]),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"sgd\", \"adam\"]),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [\"constant\", \"adaptive\",\"invscaling\"]),\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(**param)\n",
    "\n",
    "    mlp.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "    )\n",
    "\n",
    "    preds = mlp.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(valid_y, pred_labels)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "ag-vI5BQf_I4",
    "outputId": "3e5a83bf-6d60-48a2-b4ce-ca23bfae2c77"
   },
   "outputs": [],
   "source": [
    "#Fit MLP.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(alpha=1.0026228802456412, activation = 'tanh', solver = 'adam', learning_rate = 'adaptive')\n",
    "\n",
    "mlp.fit(x_rs, y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThGrnHQef_I4"
   },
   "outputs": [],
   "source": [
    "#Make predictions on the test set based on the trained model.\n",
    "\n",
    "preds_mlp = mlp.predict(x_test)\n",
    "\n",
    "probs_mlp = mlp.predict_proba(x_test)\n",
    "probs_mlp = probs_mlp[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8Gzktuhf_I5",
    "outputId": "19499ea0-0708-479c-c651-122a4ee0cac6"
   },
   "outputs": [],
   "source": [
    "#Evaluate MLP model.\n",
    "\n",
    "mlp_precision = precision_score(preds_mlp,y_test)\n",
    "mlp_recall = recall_score(preds_mlp,y_test)\n",
    "mlp_f1 = f1_score(preds_mlp,y_test)\n",
    "mlp_acc = accuracy_score(preds_mlp,y_test)\n",
    "mlp_mcc = matthews_corrcoef(y_test, preds_mlp)\n",
    "mlp_auroc = roc_auc_score(y_test, probs_mlp)\n",
    "\n",
    "print(\"Precision: %.3f\" % (mlp_precision))\n",
    "print(\"Recall: %.3f\" % (mlp_recall))\n",
    "print(\"F1 Score: %.3f\" %(mlp_f1))\n",
    "print('Accuracy: %.3f' % (mlp_acc))\n",
    "print('MCC: %.3f' % (mlp_mcc))\n",
    "print('AUROC: %.3f' % (mlp_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IaFNJHs6f_I5",
    "outputId": "cbbd551b-7609-4c68-fdc1-8c4b68577747"
   },
   "outputs": [],
   "source": [
    "#Evaluate MLP model (PRC and AUPRC).\n",
    "\n",
    "mlp_precision, mlp_recall, _ = precision_recall_curve(y_test, probs_mlp)\n",
    "mlp_auprc = auc(mlp_recall, mlp_precision)\n",
    "\n",
    "print('AUPRC: %.3f' % (mlp_auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udYNHsFDf_I5"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision and recall for calculation purposes.\n",
    "\n",
    "mlp_precision = precision_score(preds_mlp,y_test)\n",
    "mlp_recall = recall_score(preds_mlp,y_test)\n",
    "\n",
    "mlp_results = [mlp_precision, mlp_recall, mlp_f1, mlp_acc, mlp_mcc, mlp_auroc, mlp_auprc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7A1QzNEf_I5"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision recall curve for plotting purposes.\n",
    "\n",
    "mlp_precision, mlp_recall, _ = precision_recall_curve(y_test, probs_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI3bNTU5f_I5"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGzQiW9Uf_I5",
    "outputId": "bdd44ee8-25a9-4ffa-dabe-9b5b4beaf866"
   },
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for Random Forest.\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = x_rs, y_rs\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "\n",
    "    param = {\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\",\"log2\", None]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 100),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 2000, 100),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4, 1),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10, 1),\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**param)\n",
    "\n",
    "    rf.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "    )\n",
    "\n",
    "    preds = rf.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(valid_y, pred_labels)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    rf_params = {}\n",
    "\n",
    "    for key, value in trial.params.items():\n",
    "        rf_params[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "Edd1Gtslf_I6",
    "outputId": "12d59490-bf58-4650-ada2-72ef48a9bd78"
   },
   "outputs": [],
   "source": [
    "#Fit Random Forest.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(**rf_params)\n",
    "\n",
    "rf.fit(x_rs,y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9NKDKzNf_I6"
   },
   "outputs": [],
   "source": [
    "#Make predictions on the test set based on the trained model.\n",
    "\n",
    "preds_rf = rf.predict(x_test)\n",
    "\n",
    "probs_rf = rf.predict_proba(x_test)\n",
    "probs_rf = probs_rf[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb9YRHxtf_I6",
    "outputId": "02d62272-e945-43fb-9f37-91bcc6e6b993"
   },
   "outputs": [],
   "source": [
    "#Evaluate Random Forest model.\n",
    "\n",
    "rf_precision = precision_score(preds_rf,y_test)\n",
    "rf_recall = recall_score(preds_rf,y_test)\n",
    "rf_f1 = f1_score(preds_rf,y_test)\n",
    "rf_acc = accuracy_score(preds_rf,y_test)\n",
    "rf_mcc = matthews_corrcoef(y_test, preds_rf)\n",
    "rf_auroc = roc_auc_score(y_test, probs_rf)\n",
    "\n",
    "print(\"Precision: %.3f\" % (rf_precision))\n",
    "print(\"Recall: %.3f\" % (rf_recall))\n",
    "print(\"F1 Score: %.3f\" %(rf_f1))\n",
    "print('Accuracy: %.3f' % (rf_acc))\n",
    "print('MCC: %.3f' % (rf_mcc))\n",
    "print('AUROC: %.3f' % (rf_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bkw2BgyMf_I6",
    "outputId": "8063be8b-2b0f-44a4-fa7f-8a5b7867a557"
   },
   "outputs": [],
   "source": [
    "#Evaluate Random Forest model (PRC and AUPRC).\n",
    "\n",
    "rf_precision, rf_recall, _ = precision_recall_curve(y_test, probs_rf)\n",
    "rf_auprc = auc(rf_recall, rf_precision)\n",
    "\n",
    "print('AUPRC: %.3f' % (rf_auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBgn6iEdf_I7"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision and recall for calculation purposes.\n",
    "\n",
    "rf_precision = precision_score(preds_rf,y_test)\n",
    "rf_recall = recall_score(preds_rf,y_test)\n",
    "\n",
    "rf_results = [rf_precision, rf_recall, rf_f1, rf_acc, rf_mcc, rf_auroc, rf_auprc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52frI6mnf_I7"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision recall curve for plotting purposes.\n",
    "\n",
    "rf_precision, rf_recall, _ = precision_recall_curve(y_test, probs_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5tz-jpFoOHz"
   },
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tV3AQwVotD66"
   },
   "outputs": [],
   "source": [
    "from optuna.samplers import TPESampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFFJOt_hoR4K",
    "outputId": "aa597c11-5481-4d9d-e607-8c93248b829c"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Logistic Regression.\n",
    "\n",
    "def objective(trial):\n",
    "    data, target = x_rs, y_rs\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "\n",
    "    param = {\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l2\"]),\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-4, 1e4, log=True),\n",
    "        \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\", 100, 2000, 100),\n",
    "        \"random_state\": 31,\n",
    "    }\n",
    "\n",
    "    logreg = LogisticRegression(**param)\n",
    "\n",
    "    logreg.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "    )\n",
    "\n",
    "    preds = logreg.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    auc = sklearn.metrics.roc_auc_score(valid_y, pred_labels)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    logreg_params = {}\n",
    "\n",
    "    for key, value in trial.params.items():\n",
    "        logreg_params[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "_wXpB9z6oa-x",
    "outputId": "476296aa-55bf-4b6a-edca-f982d13585d7"
   },
   "outputs": [],
   "source": [
    "#Fit Logistic Regression.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(**logreg_params)\n",
    "\n",
    "logreg.fit(x_rs,y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OA3tnrn5olgZ"
   },
   "outputs": [],
   "source": [
    "#Make predictions on the test set based on the trained model.\n",
    "\n",
    "preds_logreg = logreg.predict(x_test)\n",
    "\n",
    "probs_logreg = logreg.predict_proba(x_test)\n",
    "probs_logreg = probs_logreg[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrhkZbKHo3Ds",
    "outputId": "b0e85a85-31f7-4c43-f318-5325c2a1b0a4"
   },
   "outputs": [],
   "source": [
    "#Evaluate Logistic Regression model.\n",
    "\n",
    "logreg_precision = precision_score(preds_logreg,y_test)\n",
    "logreg_recall = recall_score(preds_logreg,y_test)\n",
    "logreg_f1 = f1_score(preds_logreg,y_test)\n",
    "logreg_acc = accuracy_score(preds_logreg,y_test)\n",
    "logreg_mcc = matthews_corrcoef(y_test, preds_logreg)\n",
    "logreg_auroc = roc_auc_score(y_test, probs_logreg)\n",
    "\n",
    "print(\"Precision: %.3f\" % (logreg_precision))\n",
    "print(\"Recall: %.3f\" % (logreg_recall))\n",
    "print(\"F1 Score: %.3f\" %(logreg_f1))\n",
    "print('Accuracy: %.3f' % (logreg_acc))\n",
    "print('MCC: %.3f' % (logreg_mcc))\n",
    "print('AUROC: %.3f' % (logreg_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlYHsLjUo5pX",
    "outputId": "5c785029-f251-49fc-f526-8fe6d456f0b3"
   },
   "outputs": [],
   "source": [
    "#Evaluate Logistic Regression model (PRC and AUPRC).\n",
    "\n",
    "logreg_precision, logreg_recall, _ = precision_recall_curve(y_test, probs_logreg)\n",
    "logreg_auprc = auc(logreg_recall, logreg_precision)\n",
    "\n",
    "print('AUPRC: %.3f' % (logreg_auprc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jG1XMB0o_vV"
   },
   "outputs": [],
   "source": [
    "#Recalculate precision and recall for calculation purposes.\n",
    "\n",
    "logreg_precision = precision_score(preds_logreg,y_test)\n",
    "logreg_recall = recall_score(preds_logreg,y_test)\n",
    "\n",
    "logreg_results = [logreg_precision, logreg_recall, logreg_f1, logreg_acc, logreg_mcc, logreg_auroc, logreg_auprc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmCGtnC_f_I9"
   },
   "source": [
    "# ROC, PR, and Calibration Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "Py2oNmN2f_I9",
    "outputId": "565c92f3-5aee-483b-9fd3-a788320058c5"
   },
   "outputs": [],
   "source": [
    "f = pyplot.figure()\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(12)\n",
    "\n",
    "xgb_fpr, xgb_tpr, _ = roc_curve(y_test, probs_xgb)\n",
    "pyplot.plot(xgb_fpr, xgb_tpr, label='XGBoost AUROC: {:.3f}'.format(xgb_auroc), color='r')\n",
    "\n",
    "lgb_fpr, lgb_tpr, _ = roc_curve(y_test, probs_lgb)\n",
    "pyplot.plot(lgb_fpr, lgb_tpr, label='LightGBM AUROC: {:.3f}'.format(lgb_auroc), color='g')\n",
    "\n",
    "cb_fpr, cb_tpr, _ = roc_curve(y_test, probs_cb)\n",
    "pyplot.plot(cb_fpr, cb_tpr, label='CatBoost AUROC: {:.3f}'.format(cb_auroc), color = 'b')\n",
    "\n",
    "mlp_fpr, mlp_tpr, _ = roc_curve(y_test, probs_mlp)\n",
    "pyplot.plot(mlp_fpr, mlp_tpr, label='Multi-Layer Perceptron AUROC: {:.3f}'.format(mlp_auroc), color = 'c')\n",
    "\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, probs_rf)\n",
    "pyplot.plot(rf_fpr, rf_tpr, label='Random Forest AUROC: {:.3f}'.format(rf_auroc), color = 'm')\n",
    "\n",
    "logreg_fpr, logreg_tpr, _ = roc_curve(y_test, probs_logreg)\n",
    "pyplot.plot(logreg_fpr, logreg_tpr, label='Logistic Regression AUROC: {:.3f}'.format(logreg_auroc), color = 'y')\n",
    "\n",
    "pyplot.plot([0, 1], [0, 1], linestyle = '--')\n",
    "\n",
    "pyplot.title('Receiver Operating Characteristic Curve', loc='center', fontsize = 20, fontweight = 'heavy', pad = 20)\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate', fontsize = 16, labelpad = 10)\n",
    "pyplot.ylabel('True Positive Rate', fontsize = 16, labelpad = 10)\n",
    "pyplot.tick_params(axis=\"y\",direction=\"out\")\n",
    "pyplot.tick_params(axis=\"x\",direction=\"out\")\n",
    "\n",
    "# show the legend\n",
    "leg = pyplot.legend(loc = 'lower right', fontsize = 12)\n",
    "\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "ExHjuQJHf_I9",
    "outputId": "8d45094c-d4f3-49f5-9bd5-f8c9cfdcc0cb"
   },
   "outputs": [],
   "source": [
    "f = pyplot.figure()\n",
    "f.set_figwidth(12)\n",
    "f.set_figheight(12)\n",
    "\n",
    "pyplot.plot(xgb_recall, xgb_precision, label='XGBoost AUPRC: {:.3f}'.format(mlp_auprc), color = 'r')\n",
    "pyplot.plot(lgb_recall, lgb_precision, label='LightGBM AUPRC: {:.3f}'.format(lgb_auprc), color = 'g')\n",
    "pyplot.plot(cb_recall, cb_precision, label='CatBoost AUPRC: {:.3f}'.format(cb_auprc), color = 'b')\n",
    "pyplot.plot(mlp_recall, mlp_precision, label='Multi-Layer Perceptron AUPRC: {:.3f}'.format(mlp_auprc), color = 'c')\n",
    "pyplot.plot(rf_recall, rf_precision, label='Random Forest AUPRC: {:.3f}'.format(rf_auprc), color = 'm')\n",
    "pyplot.plot(logreg_recall, logreg_precision, label='Logistic Regression AUPRC: {:.3f}'.format(logreg_auprc), color = 'y')\n",
    "\n",
    "pyplot.title('Precision Recall Curve', loc='center', fontsize = 20, fontweight = 'heavy', pad = 20)\n",
    "#axis labels\n",
    "pyplot.xlabel('Recall', fontsize = 16, labelpad = 10)\n",
    "pyplot.ylabel('Precision', fontsize = 16, labelpad = 10)\n",
    "# show the legend\n",
    "leg = pyplot.legend(loc = 'lower right', fontsize = 12)\n",
    "\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdEZgkVqboQ2"
   },
   "source": [
    "#SHAP Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnPSuXLPbnRm",
    "outputId": "6330e9ec-1e25-4d61-9211-1ee678ecd5a6"
   },
   "outputs": [],
   "source": [
    "# Fits the explainer\n",
    "lgb_explainer = shap.Explainer(lgb.predict, x_test)\n",
    "xgb_explainer = shap.Explainer(xgb.predict, x_test)\n",
    "cb_explainer = shap.Explainer(cb.predict, x_test)\n",
    "mlp_explainer = shap.Explainer(mlp.predict, x_test)\n",
    "rf_explainer = shap.Explainer(rf.predict, x_test)\n",
    "logreg_explainer = shap.Explainer(logreg.predict, x_test)\n",
    "\n",
    "# Calculates the SHAP values - It takes some time\n",
    "lgb_shap_values = lgb_explainer(x_test)\n",
    "xgb_shap_values = xgb_explainer(x_test)\n",
    "cb_shap_values = cb_explainer(x_test)\n",
    "mlp_shap_values = mlp_explainer(x_test)\n",
    "rf_shap_values = rf_explainer(x_test)\n",
    "logreg_shap_values = logreg_explainer(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XSOmSlwbxtF"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def print_feature_importances_shap_values(shap_values, features):\n",
    "    '''\n",
    "    Prints the feature importances based on SHAP values in an ordered way\n",
    "    shap_values -> The SHAP values calculated from a shap.Explainer object\n",
    "    features -> The name of the features, on the order presented to the explainer\n",
    "    '''\n",
    "    # Calculates the feature importance (mean absolute shap value) for each feature\n",
    "    importances = []\n",
    "    for i in range(shap_values.values.shape[1]):\n",
    "        importances.append(np.mean(np.abs(shap_values.values[:, i])))\n",
    "    # Calculates the normalized version\n",
    "    importances_norm = softmax(importances)\n",
    "    # Organize the importances and columns in a dictionary\n",
    "    feature_importances = {fea: imp for imp, fea in zip(importances, features)}\n",
    "    feature_importances_norm = {fea: imp for imp, fea in zip(importances_norm, features)}\n",
    "    # Sorts the dictionary\n",
    "    feature_importances = {k: v for k, v in sorted(feature_importances.items(), key=lambda item: item[1], reverse = True)}\n",
    "    feature_importances_norm= {k: v for k, v in sorted(feature_importances_norm.items(), key=lambda item: item[1], reverse = True)}\n",
    "    # Prints the feature importances\n",
    "    for k, v in feature_importances.items():\n",
    "        print(f\"{k} -> {v:.4f} (softmax = {feature_importances_norm[k]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "vv0j8azEbz0t",
    "outputId": "656bd457-b675-487c-d670-8ceffb7ad790"
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(xgb_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "a3_1Ykkcb11k",
    "outputId": "67e494d9-b8b5-4293-84c5-7b948431db1c"
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(lgb_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "dTgmmF2Nb4D7",
    "outputId": "d1c4b8e9-a1c4-4fcd-a0b8-c0f75e4f93d7"
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(cb_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "q2GHtWm5b6bI",
    "outputId": "18361257-89d3-49fc-9cbc-cbf6b88a2a3f"
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(mlp_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "ch1GbFFOb8_O",
    "outputId": "16fc09ef-7914-4ccb-e9d1-a49ec8e5d157"
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(rf_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "ZHU9C7S-p5yl",
    "outputId": "7d5efbc4-5c96-43e7-ac5f-e0b6ba97b5fd"
   },
   "outputs": [],
   "source": [
    "shap.plots.bar(logreg_shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Axf4eSXBapiz"
   },
   "source": [
    "#Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "JFtqqsTGf_I-",
    "outputId": "f9c98108-b432-4bb9-da69-2d522e31c32c"
   },
   "outputs": [],
   "source": [
    "results = {'XGBoost':xgb_results, 'LightGBM':lgb_results, 'CatBoost':cb_results, 'Multi-Layer Perceptron':mlp_results, 'Random Forest':rf_results, 'Logistic Regression':logreg_results}\n",
    "\n",
    "results = pd.DataFrame(results, columns = ['XGBoost', 'LightGBM', 'CatBoost', 'Multi-Layer Perceptron', 'Random Forest', 'Logistic Regression'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "KuZUhoKGf_I-",
    "outputId": "958507ad-9cb4-45d3-e562-6a83953e26e4"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'XGBoost':xgb_results, 'LightGBM':lgb_results, 'CatBoost':cb_results, 'Multi-Layer Perceptron':mlp_results, 'Random Forest': rf_results, 'Logistic Regression': logreg_results})\n",
    "\n",
    "results = results.T\n",
    "\n",
    "results.columns = ['Precision', 'Recall', 'F1', 'Accuracy', 'MCC', 'AUROC', 'AUPRC']\n",
    "\n",
    "results.to_csv('./DMVO-NIHSS Shift/algorithm_performance.csv')\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
